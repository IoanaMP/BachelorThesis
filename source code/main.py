# -*- coding: utf-8 -*-
"""Copy lkrelu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_rHsgeb7HaizuVNg2SS-9EEa4NbSENqd
"""

!pip install emnist
import numpy as np
import tensorflow as tf
from keras.models import Sequential
from keras.models import load_model, model_from_json
from keras.layers import Dropout, Activation, Dense, Input, InputLayer, Flatten, BatchNormalization, LeakyReLU
from keras.layers.convolutional import Conv2D, MaxPooling2D 
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
from keras.constraints import maxnorm
from keras.utils import np_utils
from sklearn.model_selection import KFold
from emnist import list_datasets, extract_training_samples, extract_test_samples 
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score,confusion_matrix
import matplotlib.ticker as ticker
from sklearn.model_selection import KFold

characters = ['0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']


X_train, y_train = extract_training_samples('byclass')
X_test, y_test = extract_test_samples('byclass')


fig1, axes1 = plt.subplots(4, 8, figsize=(12,8))
i=15
for i in range(32):
     ax = axes1[i//8, i%8]
     ax.imshow(X_test[i], cmap='gray_r')
     ax.set_title('Label: {}'.format(y_test[i]))
plt.tight_layout()
plt.show()

#------------------- Reshape and normalization ---------------------------------
y_train = y_train-1
y_test = y_test-1

reshape_value = X_train.shape[1]*X_train.shape[2]
X_train = X_train.reshape(X_train.shape[0], reshape_value)
X_test = X_test.reshape(X_test.shape[0], reshape_value)
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

X_train /= 255
X_test /= 255


X_train = X_train.reshape(X_train.shape[0], 1,28,28)
X_test = X_test.reshape(X_test.shape[0], 1,28,28)
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')


Y_train = np_utils.to_categorical(y_train)
Y_test = np_utils.to_categorical(y_test)

#------------------------------- Model -----------------------------------------
in_shape = (1,28,28)

'''
#For 3Fold add this code
kfold = KFold(n_splits=2, shuffle=True)
in_shape = (1,28,28)
fold = 1
for train, test in kfold.split(X_train, Y_train):
'''

model = Sequential()
model.add(Conv2D(28, (3, 3), input_shape=in_shape, padding='same'))
model.add(LeakyReLU(alpha=0.05)) 
# model.add(Activation('relu')) was also used instead of Leaky-ReLU
model.add(Conv2D(28, (3, 3), input_shape=(3, 28, 28), padding='same'))
model.add(LeakyReLU(alpha=0.05))
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(Conv2D(32, (3, 3), padding='same'))
model.add(LeakyReLU(alpha=0.05))
model.add(MaxPooling2D((2,2), padding='same'))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(Conv2D(64, (3, 3), padding='same'))
model.add(LeakyReLU(alpha=0.05))
model.add(MaxPooling2D((2,2), padding='same'))
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(Flatten())
model.add(Dropout(0.2))

model.add(Dense(28, kernel_constraint=maxnorm(3)))
model.add(LeakyReLU(alpha=0.05))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(Dense(52, kernel_constraint=maxnorm(3)))
model.add(LeakyReLU(alpha=0.05))
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(Dense(256,activation = 'linear'))
model.add(Dense(256, activation='softmax'))

model.summary()

optimizer = Adam(learning_rate=0.001)
model.compile(loss='categorical_crossentropy',
              optimizer=optimizer,
              metrics=['accuracy'])

history = model.fit(X_train, Y_train, epochs=25, batch_size = 256, verbose =1, validation_data=(X_test, Y_test))


score = model.evaluate(X_test, Y_test, verbose=1)
print("\nValidation score:", score[0])
print('Validation accuracy:', score[1])

'''
#Increase fold to go to the next iteration
fold = fold+1
'''

#------------------------------- Plot Accuracy ---------------------------------
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
#-------------------------------- Plot Loss ------------------------------------
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

#----------------------------- Model Evaluation --------------------------------

score = model.evaluate(X_test, Y_test, verbose=1)
print("\nValidation score:", score[0])
print('Validation accuracy:', score[1])
pred=model.predict(X_test)

res=np.argmax(pred,axis=1)
rounded_labels=np.argmax(Y_test, axis=1)
acc = accuracy_score(rounded_labels,res)

#------------------------ Plot Confusion Matrix --------------------------------
confusion_matrix(rounded_labels,res)
predicted = []
correct = []
for e in range(len(res)):
  predicted.append(chr(res[e]))

for e in range(len(rounded_labels)):
  correct.append(chr(rounded_labels[e]))
mat_con = (confusion_matrix(correct, predicted))


fig, px = plt.subplots(figsize=(62, 62))
px.matshow(mat_con, cmap=plt.cm.YlOrRd)
px.set_xlabel('Predicted labels');
px.set_ylabel('True labels'); 
px.set_title('Confusion Matrix'); 
px.xaxis.set_ticklabels(['']+characters); 
px.yaxis.set_ticklabels(['']+characters);
px.xaxis.set_major_locator(ticker.MultipleLocator(1))
px.yaxis.set_major_locator(ticker.MultipleLocator(1))
for m in range(mat_con.shape[0]):
    for n in range(mat_con.shape[1]):
        px.text(x=m,y=n,s=mat_con[m, n], va='center', ha='center', size='xx-large')

plt.xlabel('Predictions', fontsize=16)
plt.ylabel('Actuals', fontsize=16)
plt.title('Confusion Matrix', fontsize=15)
plt.savefig('confusion_matrix_5.png')
plt.show()

#----------------------------- Saving the model --------------------------------

model.save('Trained_model.h5')